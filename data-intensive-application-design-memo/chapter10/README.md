## バッチ処理

- サービス（オンライン処理）
  - REST とか
- バッチ処理システム（オフラインシステム）
  - 時間がかかる処理を裏側で実行するシステム。
  - Hadoop
- ストリーム処理（純リアルタイム）
  - オンライン処理とは切り離し、小さなデータを低レイテンシで実行する。

### Unix のツールによるバッチ処理

- 単純なログ分析
  - cat で sort とかで組み合わせて行える。
  - 数 GB くらいのファイルでも数秒位でできる。
  - これは pipe があるために行単位でプログラムができているため
    - Unix の哲学
      - 一つのことをうまくこなすものを作る
      - データを別の方法で操作する必要があれば、別のものに繋げる
    - ロジックと結線の分離
      - 疎結合、遅延結合、制御の反転
      - それぞれのプログラムの結果をどうするのも自由。
        - ファイルに書き込んでもよいし繋げても良い

### MapReduce と分散ファイルシステム

- MapReduce ジョブの実行
  - 入力ファイル群を読み取りレコードに分割する
  - mapper 関数を呼び、key と value を取り出す
  - sort する
  - reducer 関数を呼ぶ。

知っているので割愛

### バッチワークフローの出力

- 検索インデックスの構築
- バッチ処理の出力としてのキーバリューストア
  - ML システムの学習済みモデル

### Hadoop と分散データベースとの比較

- ストレージの多様性
  - Hadoop 自体のデータはスキーマレスである上にそのフォーマットも制限されない
  - MPP はストレージフォーマットはストレージエンジンに依存
    - データは生のほうが良い
- 頻繁な障害に備えた設計
  - バッチ処理は失敗に対してユーザーに影響するわけではないので、フォールトに敏感ではない
  - MapReduce の粒度ではタスクに障害が発生したら、ここにリトライを発生させる
  - MPP データベースはクエリ全体を中断し、再実行しないといけない

### MapReduce を超えて

- 中間的な状態の実体化
  - MapReduce には中間状態がある
    - MapReduce の i/O は実態のあるファイルになる。
    - Unix の場合は pipeline で処理できるが MapReduce の場合はできない
    - mapper と reducer が読み書きしたデータは別のプロセスに連携されることはなく、独立している。冗長的である
  - データフローエンジン
    - 複数の処理のステージを経るデータの流れを明示的にモデル化したもの: Spark など
  - 耐障害性
    - 中間データを HDFS 上に持つことは中間状態を永続化されているので、耐障害性が高い
- グラフとイテレーティブな処理
  - Pregal の処理モデル
    - mapper は reducer にメッセージを送信するが、それをグラフとして捉えた
    - Pregal は一度だけ行き先の頂点で処理されることを保証するため、全ての頂点の状態に対してチェックポイント処理を行うことで実現できている

### 高レベル API と様々な言語

- 宣言的なクエリ言語への移行
- 様々な領域への特化
  - 統計、数値処理
