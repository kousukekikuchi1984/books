## ストリーム処理

### イベントストリームの転送

- 用語
  - ストリーム処理の文脈においてはイベントはレコードを意味する
  - 発生したことの詳細が含まれているイミュータブルなオブジェクト
  - 送信者 = producer = publisher
  - 受信者 = consumer = subscriber
- 仕組み
  - producer はデータストアにイベントを書き込む
  - consumer はデータストアにポーリングを行い、最後の実行以降のイベントがないかを確認する
- 問題
  - ポーリング頻度が高くなると新しいイベントが返される率が低くなる
    - この際は通知を使うべき
- メッセージングシステム
  - 直接 producer から consumer にメッセージを渡す
    - メッセージが失われる場合が多いので、その点をアプリケーション側で意識する必要がある。
- メッセージブローカー
  - 永続化などの手法を提供する。
  - queing されるがバックログのキューがあれば遅れる。
    - cache にはなく永続化されたデータのみの場合は特性上データを見るため
- メッセージブローカーとデータベースの比較
  - XA や JTA を使って Two-phase Commit プロトコルに参加できるので、メッセージブローカーは DB に近いように見える
  - broker は consumer にデータを渡したらデータを削除する
  - broker は基本メモリにあるデータのみを参照する。
- 複数のコンシューマー
  - ロードバランシング
    - メッセージをどの consumer に届けるか決めている方法
  - ファンアウト
    - 全てのメッセージを全ての consumer に配信する方法
- 承認と再配信
  - メッセージが失われないことを保証するために、承認という機能がある
  - クライアントはメッセージを処理し終えた時点で明示的にブローカーにそのことを伝える
  - ブローカーはキューからそのメッセージを削除する -　要するに subscriber はもらったと ack を返す
  - ack がもらえなかった場合はブローカーは別のコンシューマーにメッセージを渡す
  - クラッシュを検知してから別コンシューマーにメッセージが送られるので、順番がずれる。

### パーティション化されたログ

- メッセージブローカーはメッセージは一時的なものであるという思想に基づいている。
- 永続化という概念をメッセージに持ち込むものがログベースメッセージブローカー
- メッセージストレージのログの利用
  - 基礎
    - log-structured storage engine + write-ahead log
    - プロデューサーはメッセージをログの末尾に追記する
    - コンシューマーはログの追記を監視する
  - これを partition 化する方法もある。
    - partition 内では単調増加すうシークエンス番号を用いて読み取る。
    - メッセージには順序が正しく整列されている。
    - さらにこれを replication することで耐障害性と 1M messages/s が実現できる。
    - Kafka, DistributedLog
  - スループットが高い必要があり、メッセージの順序が重要な場合はパーティーションかされたログのアプローチが良い
    - 逆にそれ以外は JMS/AMQP スタイルのメッセージブローカーが好ましい

### データベースとストリーム

- システムの同期の保持
  - ストレージ、クエリ、処理の要求を単独では満たせないために、複数のシステムを使いそれらのデータを同期させておかないといけない
  - DWH の場合は ETL プロセスで行われる
  - dual writes
    - アプリケーション側がデータの更新が行われた際に、別システムのデータも更新しにいく
    - race condition が問題になる
- 変更データのキャプチャ
  - change data capture
  - データベースに書かれた全てのデータの変更を観察し、それを他のシステムへレプリケーションできる形態で取り出す
  - 書き込まれた変更がすぐにストリームとして利用できる
- イベントソーシング
  - CDC に似ているが DDD コミュニティで開発された手法
  - イベントに対応して、データ管理タスクを実行する
  - 保存されたイベントからビューを具体化することによって、一般的に CQRS パターンと組み合わされます。
- 状態、ストリーム、イミュタビリティ
  - immutability -> 会計
    - 各々のトランザクションは台帳に記載
    - 間違いがあった場合は間違いを補正する取引を追加
    - これは間違いがあった箇所が重要であるとわかるため
  - イミュータブルなイベントログからミュータブルな状態を分離すると
    - 同じイベントログから読み取りの表現が導出できる
    - イベントログからデータベースへの明示的な変換ステップがあれば、データベースインデータ投入ができる
    - データ書き込み形式からデータ読み込み形式を分離すると、様々は view がつかえる
      - この時の問題は、非同期で動くために書き込みが反映されていない場合がある
      - 同期的にする -> XA
      - イベントログから算出すると、アトミックにできる。
  - immutable なログに関する問題
    - 断片化 -> コンパクション
    - 個人データ保護のためのデータ削除

### ストリームの処理

- ストリーム処理の利用
  - 復号イベント処理 Complex Event Processing
    - イベントストリームの解析を目的
    - 特定のイベントパターンの検出
    - 検出されたら、そのハンドラにデータを流す仕組み
  - ストリーム分析
    - 大量のイベントに対する特定期間のメトリクスや統計
  - マテリアライズドビューの管理
    - 元となるデータの全てのイベントが必要
  - ストリームでの検索
    - 検索をストリームで行う
  - メッセージパッシングと RPC
    - メッセージパッシングで PRC の代わりとなる処理はできる
    - がメッセージ配信をクラッシュが生じた時の対処が必要。
- 時間に関する考察
  - event time と processing time
    - 障害時には一部の処理時間が伸びるが、イベント時間は同じ。
    - 集計はイベント時間に基づいて行うべき
  - window の定義
    - ここ 5 分間といっても、イベントが到達するかこれからどうかが不明
    - straggler イベント（window 完了後に到達するイベント）
      - 無視
      - 訂正
  - クロック問題
    - そもそも時刻は正しい？ どこのクロックを使っている？
    - 3 つのタイムスタンプをログに記録すると良い
      - デバイスのクロックから取得したイベント発生時刻
      - デバイスのクロックから取得したイベントがサーバーへ送信された時刻
      - サーバーのクロックから取得したイベントがサーバーに受信された時刻
  - window の種類
    - tunbling window
      - 固定長で厳密に決められる
    - hopping window
      - tunbling の時間 ± hopping 時間で定義
      - ダブりを許容
    - スライディングウィンドウ
      - ある期間で起きた全てのイベントを含む
    - セッションウィンドウ
      - 期間を固定しないが時間的には全てのイベントをまとめる
- ストリームの結合
  - ストリーム-ストリーム結合
  - ストリームーテーブル結合
  - テーブル-テーブル結合
- 耐障害性
  - マイクロバッチとチェックポイント処理
    - なるべくバッチサイズを小さくして、チェックポイントを作成
  - アトミックなコミット
    - イベント処理に成功した場合のみ、その出力が有効化される
    - XA
  - 冪等性
    - リトライしても同じ処理は同じ結果を返すのであれば、問題ない
  - 障害後の状態の再構築
