## エンコーディングと進化

- ファイルに書き出したりネットワークで送信する時には、データを何らかのバイト形式でエンコードしないといけない。
  - インメモリ -> バイト への変換を encoding, seliarization, marshaling とかという
  - バイト -> インメモリ への変換を decoding, deserialization, unmarshaling とかいう
- データフォーマットとして、JSON, XML, Protobuf, Thrift, Avro
- 通信として、REST と RPC

### データエンコードのフォーマット

- pickle など言語固有の構造体を含むデータを serialize
  - 効率が悪い、セキュリティ上好ましくない、他言語で用いることができないなどのデメリットが大きい。
- JSON, XML, CSV
  - テキストフォーマットで人間に扱いやすい
  - JSON の数値は整数値と浮動小数点を数値を区別しない。
    - JSON の number が ECMAScript の Numbers に対応
    - ECMAScript の Numbers が IEEE 754 の倍精度浮動小数点数として扱われるため。
    - これにより、十分に大きな数字の場合はデータが狂う可能性がある
- JSON をバイト表現したものが、MessagePack など色々ある。
  - データ削減量がわずかだが、人間が読めなくなる
- Thrift や Protocol Buffer
  - MessagePack よりもデータ削減量が大きい
  - タグ番号が振られていないものは無視する
  - 新しいタグ番号を振られた場合はスキーマを追加できる。
  - 既存のスキーマを変更することができない。
- Avro
  - Hadoop 用のユースケースに Thrift が適合しなかったので、作られた形式
  - 人間が読めるスキーマと機械が読みやすいスキーマの両方がある。
  - reader と writer の schema が一致し値得る必要がある
    - 順番が異なっていても大丈夫。SQL と同じ
- データフロー
  - データベースの場合は後方互換性を担保する必要がある。
    - 新しいバージョンのコードによって古いバージョンのコードで生成されたデータを読み込むことがありうるから。
